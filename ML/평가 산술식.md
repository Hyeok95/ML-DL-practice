
✔️들어가기 이전에

* 분류모델을 평가하기 위해서는 TP, TN, FP, FN의 개념을 이해해야 합니다. <br>
TP(True Positive) : 실제로 Positive인 정답을 Positive라고 예측<br>
TN(True Negative) : 실제로 Negative인 정답을 Negative라고 예측<br>
FP(False Positive) : 실제론 Negative인 정답을 Positive라고 예측 <br>
FN(False Negative) : 실제로 Positive인 정답을 Negative라고 예측<br>



✔️1. Accuracy(정확도) <br>
Accuracy는 전체 예측 건수에서 정답을 맞힌 건수의 비율입니다.
	
Accuracy의 특징✏️

 가장 직관적으로 모델의 성능을 나타낼 수 있는 평가지표입니다.
 domain의 편중(bias)문제가 발생할 수 있습니다.
 예를 들어, 더운 지역에 눈이오는 날 수를 예측한다고 할 때, 모두 '오지 않는다'라고만 분류기를 만들어도 분류기는 상당히 높은 정확성을 보일 것입니다. 이처럼 data자체의 domain이 불균형할 경우 문제가 생길 수 있습니다.


✔️2. Precision(정밀도) / Recall(재현율)

Precision의 특징✏️

Precision(정밀도)은 True라고 분류한 것들 중에서 실제로 True인 것의 비율입니다. <br>
PPV(Positive Predictive Value) 즉 Positive 정답률이라고도 불립니다. <br>

Recall의 특징✏️

Recall(재현율)은 실제 True인 것 중에서 True라고 예측한 것의 비율입니다. Sensitivity 혹은 Hit rate이라고도 불립니다. 

즉, Precision이나 Recall은 모두 모델이 True라고 예측한 것과 관련이 있으나, 관점이 다르다고 생각 할 수 있습니다.
Precision과 Recall은 상호보완적이기 때문에, Recall을 올리면 Precision이 내려가고, Precision을 올리면 Recall이 내려갈 수 밖에 없습니다. 
이를 보완하려 생겨난 것이 Recall과 Precision의 조화평균인 F1 score입니다.


✔️3. F1-score 

F1-score는 Recall과 Precision의 조화평균으로 모델을 평가합니다.
0에서 1사이의 값을 가지며 1에 가까울수록 좋습니다.

F1-score의 특징✏️

산술평균이 아니라 조화평균을 이용하는 이유는 두 지표(Precision, Recall)를 모두 균형있게 반영하기 위함입니다.
Accuracy와 달리 클래스 데이터가 불균형할 때도 사용하기 좋습니다. 
	

✔️3-1. Macro-F1 

데이콘 대회를 보면, 단순 평가산식으로 F1-score대신 Macro-F1 score를 사용한 대회도 많은데요,
Macro-F1점수는 클래스별/레이블별 F1-score의 평균으로 정의됩니다.

Macro-F1의 특징✏️

Macro-F1 역시 0과 1사이의 값을 가지며 1에 가까울수록 좋습니다.
Macro-F1의 경우 모든 class의 값에 동등한 중요성을 부여합니다. 즉, 비교적 적은 클래스(rare classes)에서 성능이 좋지 않다면, Macro-F1의 값은 낮게 나타날 것입니다.
Macro-F1은  먼저 class와 label의 각각 F1-score를 계산한 뒤 평균내는 방식으로 작동합니다.


이외에도 많은 F1 기반 평가산식이 존재하며, python 패키지의 sklearn.metrics.f1_score🔗를 통해 ‘micro’, ‘macro’, ‘samples’,’weighted’, ‘binary’ f1-score를 계산할 수 있습니다.




✔️4. AUC(Area under the ROC Curve)

ROC curve는 여러 임계값을 기준으로 Recall-Fallout의 변화를 시각화 한 것입니다.
Fall-out(FPR : False Positive Rate)은 실제 False인 데이터 중에서 모델이 True로 분류한 비율을 나타낸 것입니다.
ROC curve는 그래프이기 때문에 명확한 수치로써 비교하기 어렵습니다. 따라서 그래프 아래의 면적 값을 이용하고 이것이 AUC(Area Under the ROC Curve)입니다.
	AUC의 특징✏️

AUC의 최댓값은 1이고 Fall-out에 비해 Recall값이 클수록(좋은 모델일수록) 1에 가까운 값이 나옵니다.




✔️5. Logloss

Logloss는 다중 클래스 분류 모델의 평가 방법으로 쓰입니다.
데이콘에서도 운동 동작 분류 AI 경진대회🔗에서 사용되었는데요, 
Logloss는 확률 값 자체를 평가 지표로 사용합니다.
	Logloss의 특징✏️

Logloss는 분류모델에서 운이좋아서 그 값을 맞게 예측한 사람과, 실제로 그 값을 맞게 예측한 사람을 분류하는 것에 유용합니다.<br>
0.2의 확률로 1이라고 예측한 사람보다, 0.9의 확률로 1이라고 예측한 사람이 실제값이 1일 때 더 많은 점수를 얻습니다.<br>
Logloss 값은 0에 가까울수록 정확하게 예측한 것이고, 확률이 낮아질 수록 값이 급격하게 커집니다.


-------------------------------------------------------



